---
title: "Advanced Regression and Prediction"
author: "Mauricio Marcos Fajgenbaun"
date: "7/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Predicting Life Expectancy 

###Defining Colours
```{r}
color_1 <- "blue"
color_2 <- "red"
color_3 <- "yellow"
```

```{r}
#library("mice")
#library("tidyverse")
#library("ggplot2")
#library("ggcorrplot")
#library("caret")
library(corrplot)
```

### Reading Dataset

```{r}
data <- read.csv("life_expect.csv")
dim(data)
head(data)
```
As we can see, we have a total of 22 variables (21 independent features and 1 output). As my intention is to predict the life expectancy of a country, given the values of some other characteristics of the country, I will drop the variables that account for the name of the country and the year the meassures were taken. This is because, again, it will not add any important information to the analysis (maybe for other analysis, it would be useful)


# Data Preprocessing

```{r}
summary(data)
```


As we can see, we have a lot of missing value in our dataset. We get some variables, such as population with over 652 missing values! That is plenty. Also, there are some variables that have some values equal to zero. As this is a dataset taken from the WHO, we will consider that the zeros are not a mistake, but specific cases of countries where they registered that specific measure.



```{r}
data$Year <- as.factor(data$Year)
sum(apply(data, 1, anyNA))
```

As we can see, there are 1289 rows being affected by Nans. This is a huge problem, as it is almost 30% of ours rows, meaning that it is not a good idea to drop so much information. 

First, I will fill the missing values of every country, with the same information as the past (or next) year from the same country. This way, there will be consistency in eachs countries measures.


```{r}
data <- data %>%
  dplyr::group_by(Country) %>%
  fill(Population,GDP,Life.expectancy,Schooling,Income.composition.of.resources,thinness..1.19.years,thinness.5.9.years,Total.expenditure,Hepatitis.B,BMI,Alcohol,Adult.Mortality, .direction = "downup") %>%
  dplyr::ungroup()
```

```{r}
sum(apply(data, 1, anyNA))
```
We have fixed some missing values. Nevertheless, we still have 818 rows with some of them. It is easy to tell that the biggest problems are with the variables Population and GDP. Let´s see what countries have no information whatsoever regarding their population and drop them.

```{r}
bygroup <- aggregate(Population ~ Country, data=data, function(x) {sum(is.na(x))}, na.action = NULL)
```

```{r}
no_info <- bygroup$Country[bygroup$Population ==16]
no_info
```
When taking a closer look, we can see that most of the missing values in our dataset come from these countries in the list. So I decide to take them out.

```{r}
data <- filter(data, !Country %in% no_info)
summary(data)
dim(data)
sum(apply(data, 1, anyNA))
```
As we can see, now we only have 178 missing values. We have lost some information by deleting so many rows, but we still have 2298 rows. Now we can do an imputation with the library "mice".

```{r}
data <- mice(data,m=1,method="cart")
data <- complete(data)
attach(data)
```

Now, we don´t have any more missing values, we can keep on working with our dataset.


As explained before, let´s first drop the first and second column of the data frame.
```{r}
data <- data[,3:22]
dim(data)
head(data)
```

```{r}
summary(data)
```
As we can see I have now 19 predictors, from which 18 are continuous and only 1 is categorical. Here is an explanation of them:

1) Status
2) Life Expectancy
3) Adult Mortality
4) Infant Deaths
5) Alcohol
6) Percentage Expenditure
7) Hepatitis B
8) Measles
9) BMI
10) Under 5 deaths
11) Polio
12) Total Expenditure
13) Diphteria
14) HIV
15) GDP
16) Population
17) Thinness 5-9 years
18) Thinness 1-5 years
19) Income Composition of Resources
20) Schooling

As an economist, I think that a good way to start simplifying my dataset is to divide the values of GDP/Population. This way, we get GDP per cápita, a good measure that allow us to compare in a more straighforward way the amount of production of each country per person.


### Target Variable: Life Expectancy

As said before, my purpose is to predict the life expectancy of a country. Let´s first explore this variable.

```{r}
summary(data$Life.expectancy)
```
### Features (predictors)

```{r, echo=TRUE, warning=FALSE, message=FALSE, result="hide"}
features <- setdiff(colnames(data),'data')
numeric_features <- setdiff(colnames(data[,2:20]),'data')
features
```
```{r}
for (f in numeric_features) {
  hist(data[,f], main=f)
}
```

Let´s check the autocorrelation between the variables.
```{r}
correlation <- corrplot(cor(data[,2:20]),type="upper",method="circle",title="Correlation plot",mar=c(0.1,0.1,0.1,0.1))
```
As we can see, there are some variables that have a strong correlation. For exapmle, there is a perfect correlation between "under five year death" and "infant mortality". This is because they measure almost the same, but with a slight different age interval. There is also a strong correlation between "GDP" and the "percentage of expenditure". This is also logical: the richer the country, the bigger the percentage of GDP destined to the health sector.
As "under five year death" and "infant mortality" measure almost the same thing, I will drop the first one.

```{r}
datos <- data[,-10]
setdiff(colnames(datos),'data')
```


# Modeling and Prediction

First, let´s divide the training and testing set with caret.

```{r}
in_train <- createDataPartition((datos$Life.expectancy), p = 0.75, list = FALSE)  # 75% for training
training <- data[ in_train,]
testing <- data[-in_train,]
nrow(training)
nrow(testing)
```
Let´s explore the traning and testing set to be sure there is no huge bias in any of them.

```{r}
corr_life <- sort(cor(training[,2:19])["Life.expectancy",], decreasing = T)
corr=data.frame(corr_life)
ggplot(corr,aes(x = row.names(corr), y = corr_life)) + 
  geom_bar(stat = "identity", fill = "lightblue") + 
  scale_x_discrete(limits= row.names(corr)) +
  labs(x = "Predictors", y = "Life Expectancy", title = "Correlations") + 
  theme(plot.title = element_text(hjust = 0, size = rel(1.5)),
        axis.text.x = element_text(angle = 45, hjust = 1))
```
As we can see, the variable that has the strongest correlation is the income composition of resources, followed by BMI, and GDP. On the other hand, there are some variables that hold a strong negative correlation with our target, such as Adult mortality (logicaly), HIV (also logicaly) and other variables that are defined by illnesses that may cause death. The only variable that apparently has no correlation with life expectancy is "Population". Nevertheless, correlation does not necesarily imply causality, so we can not yet asses which of these predictors helps us best to predict life expectancy in a country.




